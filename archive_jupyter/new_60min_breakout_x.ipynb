{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from cnn_method import *\n",
    "from cnn_preproc_function import *\n",
    "\n",
    "import optparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras_model_configuration import *\n",
    "from keras_metric import *\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gpudevice = \"0\"\n",
    "os.environ[\"TF_MIN_GPU_MULTIPROCESSOR_COUNT\"] = \"4\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=gpudevice\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "raw_data_file =  \"./DATA/PRICE_LIQUIDASSET_30_MIN.csv\"\n",
    "target_col = TARGET_TO_PREDICT = \"EURUSD\"\n",
    "FUTURE_PERIOD_PREDICT = 1\n",
    "\n",
    "TARGET_FUNCTION = \"cumulative_returns\"\n",
    "TARGET_THRESHOLD = 0.001\n",
    "BREAKOUT_WINDOW = 60\n",
    "FLIP = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_target_2(df, target_col, FUTURE_PERIOD_PREDICT, TARGET_FUNCTION = \"cumulative_returns\", keras_preproc = True):\n",
    "    if TARGET_FUNCTION == \"cumulative_returns\":\n",
    "        TARGET_FUNCTION_R = cumulative_returns\n",
    "    elif TARGET_FUNCTION == \"mod_sharpe\":\n",
    "        TARGET_FUNCTION_R = mod_sharpe\n",
    "\n",
    "    df.loc[:,'target'] = df[target_col].rolling(window = FUTURE_PERIOD_PREDICT).apply(lambda x: TARGET_FUNCTION_R(x))\n",
    "    df.loc[:,'target'] = df['target'].shift(-FUTURE_PERIOD_PREDICT+1)\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_data_breakout_x(df, target_col, breakout_window = 60):\n",
    "    price_df = df.fillna(method = \"ffill\").dropna()\n",
    "    return_df = df.pct_change()\n",
    "\n",
    "    return_df = filter_off_trading_day(return_df, target_col)\n",
    "    filtered_index = return_df.index\n",
    "    price_df = price_df.reindex(filtered_index)\n",
    "    x_df = price_df.rolling(window = breakout_window).apply(lambda x: breakout(x)*1,raw = False)\n",
    "    return_df[\"target\"] = return_df[target_col]\n",
    "    fdf = pd.merge(x_df, return_df[[\"target\"]], left_index = True, right_index = True)\n",
    "    fdf.dropna()\n",
    "\n",
    "    return fdf\n",
    "\n",
    "def clean_data_breakout_x_2(df, target_col, breakout_window = 60):\n",
    "    price_df = df.fillna(method = \"ffill\").dropna()\n",
    "    return_df = df.pct_change()\n",
    "    return_df = filter_off_trading_day(return_df, target_col)\n",
    "    return_df[\"target\"] = return_df[target_col]\n",
    "    fdf = return_df.dropna()\n",
    "\n",
    "    return fdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Data: Done!\n"
     ]
    }
   ],
   "source": [
    "df = load_data(raw_data_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_data_breakout_x_2(df, target_col, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = create_target_2(df, \"target\", FUTURE_PERIOD_PREDICT, TARGET_FUNCTION)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "df = classify_target(df, \"target\", TARGET_THRESHOLD, FLIP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def split_df(df, end_split):\n",
    "    #Split df and get index\n",
    "    start_index, end_index = get_index_from_date(df, end_split)\n",
    "    target_col= \"target\"\n",
    "    x_columns = [j for j in df.columns if j != target_col]\n",
    "\n",
    "    #Scaling\n",
    "    # scaler = sklearn.preprocessing.MinMaxScaler(feature_range = (0,1))\n",
    "    scaler = sklearn.preprocessing.StandardScaler()\n",
    "    #Fit train_x\n",
    "    train_x_data = df[x_columns].iloc[start_index[0]:(end_index[0]+1)].values\n",
    "    scaler.fit(train_x_data)\n",
    "    #Scale all\n",
    "    df.loc[:,x_columns] = scaler.transform(df[x_columns])\n",
    "    X = df[x_columns].values\n",
    "    Y = df[target_col].values\n",
    "\n",
    "    return df, X, Y, start_index, end_index, scaler\n",
    "\n",
    "import datetime\n",
    "end_split = [datetime.datetime(2011,1,1), datetime.datetime(2013,1,1), datetime.datetime(2017,1,1)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df, X, Y, start_index, end_index, scaler = split_df(df, end_split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 10, 56)\n",
      "Number of batches per epoch: 128\n",
      "TSGenerator: Done!\n"
     ]
    }
   ],
   "source": [
    "SEQ_LEN = 10\n",
    "BATCH_SIZE = 256\n",
    "train_data_gen, val_data_gen, test_1_data_gen, test_2_data_gen, shape_x = TSGenerator(X, Y, SEQ_LEN, BATCH_SIZE, start_index, end_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57924155 3.65491071]\n"
     ]
    }
   ],
   "source": [
    "class_weights = get_class_weights(df, start_index, end_index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['EURUSD', 'EEM', 'EFA', 'EWZ', 'FXI', 'HYG', 'IAU', 'IWM', 'SPY', 'VWO',\n",
       "       'XLE', 'XLF', 'XLI', 'XLK', 'XLP', 'XLU', 'XOP', 'JNK', 'IYR', 'VEA',\n",
       "       'SLV', 'XLV', 'RSX', 'TLT', 'EWJ', 'OIH', 'GLD', 'EZU', 'KRE', 'SMH',\n",
       "       'XLB', 'XRT', 'LQD', 'EWT', 'XLY', 'VNQ', 'EWH', 'EWW', 'XBI', 'DIA',\n",
       "       'EWG', 'VGK', 'IEF', 'EMB', 'FEZ', 'AGG', 'EWC', 'USDJPY', 'AUDUSD',\n",
       "       'USDCAD', 'EURJPY', 'NZDUSD', 'hh', 'mm', 'ss', 'wkday', 'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09250290197334188"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(df.iloc[start_index[1]:end_index[1]][\"target\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_folder = \"./output/logs\"\n",
    "models_folder = \"./output/models\"\n",
    "model = rnn_model_conf_1_best(shape_x)\n",
    "adm = keras.optimizers.Adam(lr=0.005, beta_1=0.9, beta_2=0.999, epsilon=None, amsgrad=False, decay = 1e-6)\n",
    "model.compile(optimizer=adm, loss='binary_crossentropy', metrics=['accuracy', precision, f1])\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir=logs_folder)\n",
    "filepath = \"DL-{epoch:04d}-{val_loss:.4f}-{val_acc:.4f}-{val_precision:.4f}-{val_f1:.4f}\"\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\"{}/{}.model\".format(models_folder, filepath),\n",
    "                                                       monitor=\"val_loss\",\n",
    "                                                       verbose=1,\n",
    "                                                       save_best_only=False,\n",
    "                                                       save_weights_only=False,\n",
    "                                                       mode=\"auto\",\n",
    "                                                       period=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00003: saving model to ./output/models/DL-0003-0.2898-0.9075-0.0000-0.0000.model\n",
      "\n",
      "Epoch 00006: saving model to ./output/models/DL-0006-0.2995-0.9075-0.0000-0.0000.model\n",
      "\n",
      "Epoch 00009: saving model to ./output/models/DL-0009-0.3164-0.9075-0.0000-0.0000.model\n",
      "\n",
      "Epoch 00012: saving model to ./output/models/DL-0012-0.3468-0.8765-0.1239-0.0769.model\n",
      "\n",
      "Epoch 00015: saving model to ./output/models/DL-0015-0.4317-0.8653-0.1482-0.1154.model\n",
      "\n",
      "Epoch 00018: saving model to ./output/models/DL-0018-0.5248-0.8726-0.1539-0.1064.model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-7494baa299aa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m                                   \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                   \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m                                   verbose=0)\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1413\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1414\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1415\u001b[1;33m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[0;32m   1416\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1417\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m    211\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[0;32m    212\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 213\u001b[1;33m                                             class_weight=class_weight)\n\u001b[0m\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1214\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1215\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1216\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2664\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2666\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2667\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2635\u001b[0m                                 session)\n\u001b[1;32m-> 2636\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2637\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1449\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[1;32m-> 1451\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(generator=train_data_gen,\n",
    "                                  validation_data=val_data_gen,\n",
    "                                  epochs=128,\n",
    "                                  class_weight=class_weights,\n",
    "                                  callbacks=[tensorboard, checkpoint],\n",
    "                                  verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "z = dict(a =['EURUSD', 'EEM', 'EFA', 'EWZ', 'FXI', 'GDX', 'HYG', 'IAU', 'IWM', 'SPY',\n",
    "                   'USO', 'VWO', 'XLE', 'XLF', 'XLI', 'XLK', 'XLP', 'XLU', 'XOP', 'JNK',\n",
    "                   'IYR', 'VEA', 'SLV', 'XLV', 'RSX', 'TLT', 'EWJ', 'OIH', 'GLD', 'EZU',\n",
    "                   'KRE', 'SMH', 'XLB', 'XRT', 'LQD', 'EWT', 'XLY', 'VNQ', 'EWH', 'EWW',\n",
    "                   'XBI', 'DIA', 'EWG', 'VGK', 'IEF', 'EMB', 'FEZ', 'AGG', 'ITB', 'EWC',\n",
    "                   'UNG', 'USDJPY', 'GBPUSD', 'AUDUSD', 'USDCAD',\n",
    "                   'EURJPY', 'NZDUSD', 'XAGUSD'])\n",
    "#pd.DataFrame(z).sort_values(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
