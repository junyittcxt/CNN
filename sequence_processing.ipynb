{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import TimeseriesGenerator\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from cnn_preproc_function import *\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from keras_metric import *\n",
    "import keras\n",
    "import time\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\n",
    "import keras\n",
    "import os\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "DATA_PARAMS = dict()\n",
    "DATA_PARAMS[\"TARGET_TO_PREDICT\"] = \"AUDUSD\"\n",
    "DATA_PARAMS[\"FUTURE_PERIOD_PREDICT\"] = 3\n",
    "DATA_PARAMS[\"SEQ_LEN\"] = 50\n",
    "DATA_PARAMS[\"TARGET_THRESHOLD\"] = 0.001\n",
    "DATA_PARAMS[\"FLIP\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load\n",
    "df = pd.read_csv(\"./DATA/x_82_ETF_FOREX_5MIN_RETONLY.csv\")\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "df = df.set_index(\"Date\").sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean and create target\n",
    "df = filter_off_trading_day(df, target = DATA_PARAMS[\"TARGET_TO_PREDICT\"], threshold = 0.1)\n",
    "df = create_target(df, DATA_PARAMS[\"TARGET_TO_PREDICT\"], DATA_PARAMS[\"FUTURE_PERIOD_PREDICT\"], cumulative_returns)\n",
    "df = classify_target(df, \"target\", DATA_PARAMS[\"TARGET_THRESHOLD\"], DATA_PARAMS[\"FLIP\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_split = [datetime.datetime(2011,1,1), datetime.datetime(2012,1,1), datetime.datetime(2016,1,1), datetime.datetime(2018,1,1)]\n",
    "\n",
    "start_index, end_index = get_index_from_date(df, end_split)\n",
    "\n",
    "target_col= \"target\"\n",
    "x_columns = [j for j in df.columns if j != target_col]\n",
    "X = df[x_columns].values\n",
    "Y = df[target_col].values\n",
    "\n",
    "#try: model.add(Lambda(lambda x: scaler.transform(x)))\n",
    "scaler = sklearn.preprocessing.MinMaxScaler(feature_range = (0,1))\n",
    "train_x_data = df[x_columns].iloc[start_index[0]:(end_index[0]+1)].values\n",
    "scaler.fit(train_x_data)\n",
    "df.loc[:,x_columns] = scaler.transform(df[x_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "train_data_gen = TimeseriesGenerator(X, Y,\n",
    "                               length=60, sampling_rate=1,\n",
    "                               batch_size=BATCH_SIZE, \n",
    "                               shuffle=True, \n",
    "                               start_index=start_index[0], end_index=end_index[0])\n",
    "val_data_gen = TimeseriesGenerator(X, Y,\n",
    "                               length=60, sampling_rate=1,\n",
    "                               batch_size=BATCH_SIZE, \n",
    "                               shuffle=False, \n",
    "                               start_index=start_index[1], end_index=end_index[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_x = data_gen[0][0].shape\n",
    "print(shape_x)\n",
    "print(len(data_gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = df[\"target\"].iloc[start_index[0]:(end_index[0]+1)].values\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(train_y),\n",
    "                                                 train_y)\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "PATIENCE = 20\n",
    "monitor_loss = \"val_loss\"\n",
    "mode_loss = \"min\"\n",
    "models_folder = os.path.join(\"output\", \"models\")\n",
    "logs_folder = os.path.join(\"output\", \"logs\")\n",
    "init_dir(models_folder)\n",
    "init_dir(logs_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "t0 = time.time()\n",
    "\n",
    "model = Sequential()\n",
    "model.add(keras.layers.Reshape([shape_x[1],shape_x[2],1], input_shape=(shape_x[1],shape_x[2])))\n",
    "model.add(Conv2D(128, kernel_size=(15,1), activation='relu', input_shape=(shape_x[1],shape_x[2],1)))\n",
    "model.add(Conv2D(16, kernel_size=(2,1), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "adm = keras.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=None, amsgrad=False, decay = 1e-6)\n",
    "model.compile(optimizer=adm, loss='binary_crossentropy', metrics=['accuracy', precision])\n",
    "\n",
    "tensorboard = keras.callbacks.TensorBoard(log_dir=logs_folder)\n",
    "filepath = \"CNN-{epoch:03d}-{val_loss:.4f}-{val_acc:.4f}-{val_precision:.4f}\"\"\n",
    "models_dir = models_folder\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\"{}/{}.model\".format(models_folder, filepath),\n",
    "                                                   monitor=monitor_loss,\n",
    "                                                   verbose=1,\n",
    "                                                   save_best_only=True,\n",
    "                                                   save_weights_only=False,\n",
    "                                                   mode=mode_loss)\n",
    "earlystopping = keras.callbacks.EarlyStopping(monitor=monitor_loss, \n",
    "                                              mode=mode_loss,\n",
    "                                              min_delta=0, \n",
    "                                              patience=PATIENCE, \n",
    "                                              verbose=1)\n",
    "history = model.fit_generator(generator=train_data_gen,\n",
    "                              validation_data=val_data_gen, \n",
    "                              epochs=EPOCHS, \n",
    "                              class_weight=class_weights, \n",
    "                              callbacks=[tensorboard, checkpoint, earlystopping],             \n",
    "                              verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# history = model.fit(train_x, train_y, batch_size=256, validation_data=(val_x, val_y), epochs=EPOCHS, class_weight=class_weights, callbacks=[tensorboard, checkpoint, earlystopping])\n",
    "\n",
    "t1 = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
